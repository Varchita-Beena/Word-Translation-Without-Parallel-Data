{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b4740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim\n",
    "from sklearn.preprocessing import normalize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4da6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5993f28",
   "metadata": {},
   "source": [
    "The pre-trained fasttext model for english and hindi langauges are obtained from \n",
    "https://fasttext.cc/docs/en/pretrained-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "893c9702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained FastText models for English and Hindi\n",
    "\n",
    "en_embeddings = KeyedVectors.load_word2vec_format('cc.en.300.vec.gz', limit=200000)\n",
    "hi_embeddings = KeyedVectors.load_word2vec_format('cc.hi.300.vec.gz', limit=200000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee3febe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 200000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the words in vocab\n",
    "vocab_en = []\n",
    "for each in en_embeddings.key_to_index:\n",
    "    vocab_en.append(each)\n",
    "vocab_hi = []   \n",
    "for each in hi_embeddings.key_to_index:\n",
    "    vocab_hi.append(each)\n",
    "len(vocab_en), len(vocab_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37638dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings_vectors = en_embeddings.vectors\n",
    "hi_embeddings_vectors = hi_embeddings.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff3baf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and get test and train set\n",
    "combined = list(zip(en_embeddings_vectors, hi_embeddings_vectors, vocab_en, vocab_hi))\n",
    "random.shuffle(combined)\n",
    "\n",
    "z = list(zip(*combined))\n",
    "en_embeddings_vectors, hi_embeddings_vectors, vocab_en, vocab_hi = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d180542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in hindi and english 200000 200000\n",
      "First 20 words in Hindi model: ('समाचारनई', 'protagonista', 'होस्पीटेलिटी', 'लूले', 'सेंषुअल', '0.39', 'REL', 'सगल', 'स्पाइसर', 'अवस्थाओं', 'कालिम्पोंग', 'Baltimore', 'महिंदर', 'रजस्वला', 'समबडी', 'Wise', 'मन्दर', 'tgEntry', 'विषाक्तता', 'Unless')\n",
      "First 20 words in English model: ('2216', 'itchiness', 'bwwm', '4.85', 'Gherkin', 'GasketDiesel', 'Guang', 'marquetry', 'Jes', 'preceding', 'Mussorgsky', 'Dans', 'trackball', 'Swat', 'Sylar', 'niceAverage', 'Seahorse', 'Cdr', 'riot', 'L.M.')\n"
     ]
    }
   ],
   "source": [
    "# get all words in vocab for hindi and english\n",
    "# print first 20 words in to langauges\n",
    "print('Total words in hindi and english', len(vocab_hi), len(vocab_en))\n",
    "print(\"First 20 words in Hindi model:\", vocab_hi[:20])\n",
    "print(\"First 20 words in English model:\", vocab_en[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c653e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings_vectors_train = en_embeddings_vectors[:-40000]\n",
    "en_embeddings_vectors_test = en_embeddings_vectors[-40000:]\n",
    "\n",
    "hi_embeddings_vectors_train = hi_embeddings_vectors[:-40000]\n",
    "hi_embeddings_vectors_test = hi_embeddings_vectors[-40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c1e1fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_embeddings_vectors_train = np.array(en_embeddings_vectors_train)\n",
    "hi_embeddings_vectors_train = np.array(hi_embeddings_vectors_train)\n",
    "en_embeddings_vectors_test = np.array(en_embeddings_vectors_test)\n",
    "hi_embeddings_vectors_test = np.array(hi_embeddings_vectors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf03efa",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##  Intuition Behind the Domain-Adversarial Training\n",
    "\n",
    "The **goal** of \"Word Translation Without Parallel Data\" is to **align two monolingual word embedding spaces** (like English and Hindi) **without using any bilingual dictionary**.\n",
    "\n",
    "Since we **don’t know the actual translation pairs**, we want to learn a **linear mapping** `W` that aligns the source language (e.g., English) to the target language (e.g., Hindi) — so that the mapped source words **\"look like\"** target words in the vector space.\n",
    "\n",
    "To do this, we use a **domain-adversarial approach**, inspired by **GANs** (Generative Adversarial Networks):\n",
    "\n",
    "---\n",
    "\n",
    "## Two Competing Models\n",
    "\n",
    "### 1. **Discriminator (D)**:  \n",
    "- A 2-layer neural network.\n",
    "- Learns to distinguish between:\n",
    "  - Real **target embeddings** → Label `1` (after label smoothing becomes `0.8`)\n",
    "  - **Mapped source embeddings (W·X)** → Label `0`\n",
    "- It’s trying to say: \"I can tell which embeddings are **real** (from target) and which are **fake** (mapped from source).\"\n",
    "\n",
    "### 2. **Mapping Matrix (W)**:  \n",
    "- A 300×300 linear matrix (learned weights).\n",
    "- Learns to **fool the discriminator**.\n",
    "- It tries to make **mapped source embeddings look like target ones** so well that D can no longer tell them apart.\n",
    "\n",
    "---\n",
    "\n",
    "##  Training Flow\n",
    "\n",
    "###  Step 1: Train the Discriminator\n",
    "- **Goal**: Make D better at identifying real vs. mapped embeddings.\n",
    "- Input:\n",
    "  - `W·X` → mapped source embeddings → label `0`\n",
    "  - `Y` → real target embeddings → label `1` (smooth to 0.8)\n",
    "- We compute binary cross-entropy (BCE) loss and **update only the discriminator’s weights**.\n",
    "\n",
    "###  Step 2: Train the Mapping (W)\n",
    "- **Goal**: Fool the discriminator.\n",
    "- We compute:\n",
    "  - `W·X` → mapped embeddings\n",
    "  - Pass them to D, and **pretend** they’re real → label `1`\n",
    "- The discriminator will try to say \"no, you're fake\", but W is updated to **minimize this loss**, i.e., make D believe `W·X ≈ Y`.\n",
    "\n",
    "---\n",
    "\n",
    "##  This is a Minimax Game\n",
    "- **D** wants to **maximize** its ability to classify real vs fake.\n",
    "- **W** wants to **minimize** that ability — i.e., fool D.\n",
    "\n",
    "Eventually, when D can’t tell the difference between `W·X` and `Y`, the two distributions are aligned.\n",
    "\n",
    "---\n",
    "\n",
    "##  Why This Works\n",
    "Even without knowing which specific English word maps to which Hindi word, if `W` can make **the whole source distribution match the target distribution**, we’ve **implicitly aligned the spaces**.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "##  Summary\n",
    "\n",
    "| Component        | Trained Using        | Input                     | Label | Goal                                 |\n",
    "|------------------|----------------------|---------------------------|--------|---------------------------------------|\n",
    "| Discriminator (D) | BCE loss             | `Y` (real), `W·X` (fake)  | 1, 0   | Distinguish real from fake            |\n",
    "| Mapping (W)       | BCE loss via D       | `W·X`                     | 1      | Fool D → make `W·X` look real         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "243ecd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c071cc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim = 300, hidden_dim = 2048, dropout_rate = 0.1):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb41912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(discriminator, optimizer_D, real, fake, smoothing = 0.2):\n",
    "    real_labels = torch.full((real.size(0), 1), 1.0-smoothing).to(device) # all the labels will be 0.8\n",
    "    fake_labels = torch.zeros((fake.size(0), 1)).to(device)\n",
    "    \n",
    "    # train on real\n",
    "    pred_real = discriminator(real) # sending tgt_batch\n",
    "    loss_real = nn.BCELoss()(pred_real, real_labels)\n",
    "    \n",
    "    # train on fake\n",
    "    pred_fake = discriminator(fake)\n",
    "    loss_fake = nn.BCELoss()(pred_fake, fake_labels)\n",
    "    \n",
    "    loss_D = loss_real + loss_fake\n",
    "    optimizer_D.zero_grad()\n",
    "    loss_D.backward()\n",
    "    optimizer_D.step()\n",
    "    \n",
    "    return loss_D.item()\n",
    "    \n",
    "def train_mapping(discriminator, optimizer_W, W_weight, source):\n",
    "    mapped_src = torch.mm(source, W_weight)\n",
    "    mapped_src = mapped_src.to(device)\n",
    "    target_labels = torch.ones(mapped_src.size(0), 1).to(device)\n",
    "    \n",
    "    preds = discriminator(mapped_src)\n",
    "    loss = nn.BCELoss()(preds, target_labels)\n",
    "    \n",
    "    optimizer_W.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer_W.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, base_lr = 0.1, decay_rate = 0.95):\n",
    "    lr = base_lr * (decay_rate ** epoch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    \n",
    "def adversarial_training(src_embeddings, tgt_embeddings, src_embeddings_val, tgt_embeddings_val,  epochs = 50, batch_size = 32, lr = 0.1):\n",
    "    dim = src_embeddings.shape[1]\n",
    "    \n",
    "    # W for maping (linear transform)\n",
    "    W = nn.Linear(dim, dim, bias = False).to(device)\n",
    "    # discriminator model\n",
    "    discriminator = Discriminator(input_dim = dim).to(device)\n",
    "    \n",
    "    optimizer_D = optim.SGD(discriminator.parameters(), lr=lr) # discriminator optimizer\n",
    "    optimizer_W = optim.SGD(W.parameters(), lr=lr) # W discriminator\n",
    "    \n",
    "    avg_loss_D = 0\n",
    "    avg_loss_W = 0\n",
    "    avg_val_loss_D =0 \n",
    "    for epoch in range(epochs):\n",
    "        adjust_learning_rate(optimizer_W, epoch, base_lr=0.1)\n",
    "        adjust_learning_rate(optimizer_D, epoch, base_lr=0.1)\n",
    "        \n",
    "        discriminator.train()\n",
    "        indices = range((len(src_embeddings)))\n",
    "        total_loss_D = 0\n",
    "        total_loss_W = 0\n",
    "        \n",
    "        for i in range(0, len(src_embeddings), batch_size):\n",
    "            idx = indices[i : i+batch_size]\n",
    "            src_batch = torch.tensor(src_embeddings[idx], dtype = torch.float32).to(device)\n",
    "            tgt_batch = torch.tensor(tgt_embeddings[idx], dtype = torch.float32).to(device)\n",
    "            \n",
    "            src_batch = src_batch.to(device)\n",
    "            tgt_batch = tgt_batch.to(device)\n",
    "\n",
    "            # train discriminator\n",
    "            mapped_src = W(src_batch) # mapping Wx\n",
    "            loss_D = train_discriminator(discriminator, optimizer_D, tgt_batch, mapped_src) # between target and Wx\n",
    "            loss_W = train_mapping(discriminator, optimizer_W, W.weight, src_batch) # update W\n",
    "            \n",
    "            total_loss_D += loss_D\n",
    "            total_loss_W += loss_W\n",
    "            \n",
    "        avg_loss_D = total_loss_D / batch_size\n",
    "        avg_loss_W = total_loss_W / batch_size\n",
    "            \n",
    "        #print(f\"Epoch {epoch+1}/{epochs} - Discriminator loss: {total_loss_D:.4f}, W loss: {total_loss_W:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Avg Discriminator loss: {avg_loss_D:.4f}, Avg W loss: {avg_loss_W:.4f}\")\n",
    "        \n",
    "        \n",
    "        discriminator.eval()\n",
    "        # mapping is a weight matrix (not a full nn.Module), so no .eval() needed\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_loss_D = 0\n",
    "            for i in range(0, len(src_embeddings_val), batch_size):\n",
    "                idx = indices[i:i+batch_size]\n",
    "                \n",
    "                src_batch_val = torch.tensor(src_embeddings_val[idx], dtype = torch.float32).to(device)\n",
    "                tgt_batch_val = torch.tensor(tgt_embeddings_val[idx], dtype = torch.float32).to(device)\n",
    "                \n",
    "                src_batch_val = src_batch_val.to(device)\n",
    "                tgt_batch_val = tgt_batch_val.to(device)\n",
    "\n",
    "                mapped_src_val = torch.mm(src_batch_val, W.weight)\n",
    "                mapped_src_val = mapped_src_val.to(device)\n",
    "\n",
    "                preds_src = discriminator(mapped_src_val)\n",
    "                preds_tgt = discriminator(tgt_batch_val)\n",
    "\n",
    "                # Ground truth labels\n",
    "                labels_src = torch.ones((mapped_src_val.size(0), 1)).to(device)\n",
    "                labels_tgt = torch.zeros((tgt_batch_val.size(0), 1)).to(device)\n",
    "                \n",
    "                # Compute losses\n",
    "                loss_fn = nn.BCELoss()\n",
    "                loss_src = loss_fn(preds_src, labels_src)\n",
    "                loss_tgt = loss_fn(preds_tgt, labels_tgt)\n",
    "                total_loss = (loss_src + loss_tgt) / 2\n",
    "                \n",
    "                val_loss_D += total_loss.item()\n",
    "                \n",
    "            avg_val_loss_D = val_loss_D / batch_size\n",
    "\n",
    "        #print(f\"Epoch {epoch+1}/{epochs} - Val Discriminator loss: {val_loss_D:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Val Avg Discriminator loss: {avg_val_loss_D:.4f}\")\n",
    "        \n",
    "        if avg_loss_D < avg_val_loss_D:\n",
    "            # Halve the LR\n",
    "            for optimizer in [optimizer_W, optimizer_D]:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.5\n",
    "\n",
    "       \n",
    "    return W.weight.detach().cpu().numpy()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f320d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 - Avg Discriminator loss: 86.2766, Avg W loss: 4.1812\n",
      "Epoch 1/50 - Val Avg Discriminator loss: 19.8218\n",
      "Epoch 2/50 - Avg Discriminator loss: 79.1181, Avg W loss: 0.2540\n",
      "Epoch 2/50 - Val Avg Discriminator loss: 19.2847\n",
      "Epoch 3/50 - Avg Discriminator loss: 78.7397, Avg W loss: 0.1057\n",
      "Epoch 3/50 - Val Avg Discriminator loss: 18.8995\n",
      "Epoch 4/50 - Avg Discriminator loss: 78.5985, Avg W loss: 0.0767\n",
      "Epoch 4/50 - Val Avg Discriminator loss: 18.9557\n",
      "Epoch 5/50 - Avg Discriminator loss: 78.5074, Avg W loss: 0.0617\n",
      "Epoch 5/50 - Val Avg Discriminator loss: 18.5627\n",
      "Epoch 6/50 - Avg Discriminator loss: 78.4820, Avg W loss: 0.0538\n",
      "Epoch 6/50 - Val Avg Discriminator loss: 18.7545\n",
      "Epoch 7/50 - Avg Discriminator loss: 78.4473, Avg W loss: 0.0474\n",
      "Epoch 7/50 - Val Avg Discriminator loss: 18.3983\n",
      "Epoch 8/50 - Avg Discriminator loss: 78.4179, Avg W loss: 0.0424\n",
      "Epoch 8/50 - Val Avg Discriminator loss: 18.3557\n",
      "Epoch 9/50 - Avg Discriminator loss: 78.4128, Avg W loss: 0.0396\n",
      "Epoch 9/50 - Val Avg Discriminator loss: 18.4882\n",
      "Epoch 10/50 - Avg Discriminator loss: 78.3968, Avg W loss: 0.0374\n",
      "Epoch 10/50 - Val Avg Discriminator loss: 18.5583\n",
      "Epoch 11/50 - Avg Discriminator loss: 78.3766, Avg W loss: 0.0347\n",
      "Epoch 11/50 - Val Avg Discriminator loss: 18.1225\n",
      "Epoch 12/50 - Avg Discriminator loss: 78.3783, Avg W loss: 0.0319\n",
      "Epoch 12/50 - Val Avg Discriminator loss: 18.1765\n",
      "Epoch 13/50 - Avg Discriminator loss: 78.3664, Avg W loss: 0.0309\n",
      "Epoch 13/50 - Val Avg Discriminator loss: 18.2155\n",
      "Epoch 14/50 - Avg Discriminator loss: 78.3586, Avg W loss: 0.0296\n",
      "Epoch 14/50 - Val Avg Discriminator loss: 18.4254\n",
      "Epoch 15/50 - Avg Discriminator loss: 78.3487, Avg W loss: 0.0285\n",
      "Epoch 15/50 - Val Avg Discriminator loss: 18.1704\n",
      "Epoch 16/50 - Avg Discriminator loss: 78.3410, Avg W loss: 0.0277\n",
      "Epoch 16/50 - Val Avg Discriminator loss: 18.2688\n",
      "Epoch 17/50 - Avg Discriminator loss: 78.3411, Avg W loss: 0.0263\n",
      "Epoch 17/50 - Val Avg Discriminator loss: 18.3803\n",
      "Epoch 18/50 - Avg Discriminator loss: 78.3353, Avg W loss: 0.0253\n",
      "Epoch 18/50 - Val Avg Discriminator loss: 18.2775\n",
      "Epoch 19/50 - Avg Discriminator loss: 78.3302, Avg W loss: 0.0245\n",
      "Epoch 19/50 - Val Avg Discriminator loss: 18.3921\n",
      "Epoch 20/50 - Avg Discriminator loss: 78.3272, Avg W loss: 0.0237\n",
      "Epoch 20/50 - Val Avg Discriminator loss: 18.4076\n",
      "Epoch 21/50 - Avg Discriminator loss: 78.3214, Avg W loss: 0.0231\n",
      "Epoch 21/50 - Val Avg Discriminator loss: 18.3016\n",
      "Epoch 22/50 - Avg Discriminator loss: 78.3220, Avg W loss: 0.0227\n",
      "Epoch 22/50 - Val Avg Discriminator loss: 18.2873\n",
      "Epoch 23/50 - Avg Discriminator loss: 78.3179, Avg W loss: 0.0225\n",
      "Epoch 23/50 - Val Avg Discriminator loss: 18.3929\n",
      "Epoch 24/50 - Avg Discriminator loss: 78.3124, Avg W loss: 0.0221\n",
      "Epoch 24/50 - Val Avg Discriminator loss: 18.0239\n",
      "Epoch 25/50 - Avg Discriminator loss: 78.3146, Avg W loss: 0.0216\n",
      "Epoch 25/50 - Val Avg Discriminator loss: 18.5562\n",
      "Epoch 26/50 - Avg Discriminator loss: 78.3094, Avg W loss: 0.0210\n",
      "Epoch 26/50 - Val Avg Discriminator loss: 18.4049\n",
      "Epoch 27/50 - Avg Discriminator loss: 78.3111, Avg W loss: 0.0208\n",
      "Epoch 27/50 - Val Avg Discriminator loss: 18.1071\n",
      "Epoch 28/50 - Avg Discriminator loss: 78.3061, Avg W loss: 0.0206\n",
      "Epoch 28/50 - Val Avg Discriminator loss: 18.1757\n",
      "Epoch 29/50 - Avg Discriminator loss: 78.3016, Avg W loss: 0.0202\n",
      "Epoch 29/50 - Val Avg Discriminator loss: 18.3071\n",
      "Epoch 30/50 - Avg Discriminator loss: 78.3023, Avg W loss: 0.0198\n",
      "Epoch 30/50 - Val Avg Discriminator loss: 18.1816\n",
      "Epoch 31/50 - Avg Discriminator loss: 78.3017, Avg W loss: 0.0196\n",
      "Epoch 31/50 - Val Avg Discriminator loss: 18.2231\n",
      "Epoch 32/50 - Avg Discriminator loss: 78.2964, Avg W loss: 0.0190\n",
      "Epoch 32/50 - Val Avg Discriminator loss: 18.2377\n",
      "Epoch 33/50 - Avg Discriminator loss: 78.3001, Avg W loss: 0.0190\n",
      "Epoch 33/50 - Val Avg Discriminator loss: 18.4934\n",
      "Epoch 34/50 - Avg Discriminator loss: 78.2979, Avg W loss: 0.0186\n",
      "Epoch 34/50 - Val Avg Discriminator loss: 18.5654\n",
      "Epoch 35/50 - Avg Discriminator loss: 78.3022, Avg W loss: 0.0189\n",
      "Epoch 35/50 - Val Avg Discriminator loss: 18.2335\n",
      "Epoch 36/50 - Avg Discriminator loss: 78.2921, Avg W loss: 0.0186\n",
      "Epoch 36/50 - Val Avg Discriminator loss: 18.2253\n",
      "Epoch 37/50 - Avg Discriminator loss: 78.2983, Avg W loss: 0.0187\n",
      "Epoch 37/50 - Val Avg Discriminator loss: 18.2679\n",
      "Epoch 38/50 - Avg Discriminator loss: 78.2962, Avg W loss: 0.0186\n",
      "Epoch 38/50 - Val Avg Discriminator loss: 18.1323\n",
      "Epoch 39/50 - Avg Discriminator loss: 78.2893, Avg W loss: 0.0184\n",
      "Epoch 39/50 - Val Avg Discriminator loss: 18.2552\n",
      "Epoch 40/50 - Avg Discriminator loss: 78.2923, Avg W loss: 0.0182\n",
      "Epoch 40/50 - Val Avg Discriminator loss: 18.3305\n",
      "Epoch 41/50 - Avg Discriminator loss: 78.2943, Avg W loss: 0.0182\n",
      "Epoch 41/50 - Val Avg Discriminator loss: 18.8517\n",
      "Epoch 42/50 - Avg Discriminator loss: 78.2949, Avg W loss: 0.0181\n",
      "Epoch 42/50 - Val Avg Discriminator loss: 18.5535\n",
      "Epoch 43/50 - Avg Discriminator loss: 78.2928, Avg W loss: 0.0179\n",
      "Epoch 43/50 - Val Avg Discriminator loss: 18.2984\n",
      "Epoch 44/50 - Avg Discriminator loss: 78.2889, Avg W loss: 0.0180\n",
      "Epoch 44/50 - Val Avg Discriminator loss: 18.0800\n",
      "Epoch 45/50 - Avg Discriminator loss: 78.2944, Avg W loss: 0.0178\n",
      "Epoch 45/50 - Val Avg Discriminator loss: 18.5267\n",
      "Epoch 46/50 - Avg Discriminator loss: 78.2892, Avg W loss: 0.0177\n",
      "Epoch 46/50 - Val Avg Discriminator loss: 18.5011\n",
      "Epoch 47/50 - Avg Discriminator loss: 78.2872, Avg W loss: 0.0176\n",
      "Epoch 47/50 - Val Avg Discriminator loss: 18.3076\n",
      "Epoch 48/50 - Avg Discriminator loss: 78.2869, Avg W loss: 0.0175\n",
      "Epoch 48/50 - Val Avg Discriminator loss: 18.4772\n",
      "Epoch 49/50 - Avg Discriminator loss: 78.2923, Avg W loss: 0.0174\n",
      "Epoch 49/50 - Val Avg Discriminator loss: 18.3944\n",
      "Epoch 50/50 - Avg Discriminator loss: 78.2848, Avg W loss: 0.0173\n",
      "Epoch 50/50 - Val Avg Discriminator loss: 18.4263\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    return x / np.linalg.norm(x, axis=1, keepdims=True)\n",
    "\n",
    "en_embeddings_vectors_train = normalize(en_embeddings_vectors_train)\n",
    "hi_embeddings_vectors_train = normalize(hi_embeddings_vectors_train)\n",
    "\n",
    "# Train\n",
    "W_matrix = adversarial_training(en_embeddings_vectors_train, hi_embeddings_vectors_train, en_embeddings_vectors_test, hi_embeddings_vectors_test)\n",
    "np.save('unsupervised_w_matrix.npy', W_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395c3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
