{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b4740d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.linalg import svd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim\n",
    "from sklearn.preprocessing import normalize\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5993f28",
   "metadata": {},
   "source": [
    "The pre-trained fasttext model for english and hindi langauges are obtained from \n",
    "https://fasttext.cc/docs/en/pretrained-vectors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fe1b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained FastText models for English and Hindi\n",
    "\n",
    "en_embeddings = KeyedVectors.load_word2vec_format('cc.en.300.vec.gz')\n",
    "hi_embeddings = KeyedVectors.load_word2vec_format('cc.hi.300.vec.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a341e9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000000, 300), (1876653, 300))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_embeddings.vectors.shape, hi_embeddings.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e51ae51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000000, 1876653)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all the words in vocab\n",
    "vocab_en = []\n",
    "for each in en_embeddings.key_to_index:\n",
    "    vocab_en.append(each)\n",
    "vocab_hi = []   \n",
    "for each in hi_embeddings.key_to_index:\n",
    "    vocab_hi.append(each)\n",
    "len(vocab_en), len(vocab_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e471be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in hindi and english 1876653 2000000\n",
      "First 20 words in Hindi model: ['के', '।', 'है', ',', 'में', '</s>', \"'\", 'की', '.', 'का', 'से', '-', 'और', 'को', '?', 'हैं', '>', 'पर', ')', '(']\n",
      "First 20 words in English model: [',', 'the', '.', 'and', 'to', 'of', 'a', '</s>', 'in', 'is', ':', 'I', 'for', 'that', ')', '\"', '(', 'on', 'with', 'it']\n"
     ]
    }
   ],
   "source": [
    "# get all words in vocab for hindi and english\n",
    "# print first 20 words in to langauges\n",
    "print('Total words in hindi and english', len(vocab_hi), len(vocab_en))\n",
    "print(\"First 20 words in Hindi model:\", vocab_hi[:20])\n",
    "print(\"First 20 words in English model:\", vocab_en[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eca596fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word embedding for a word in hindi and english\n",
    "hindi_word_vector = hi_embeddings[vocab_hi.index('राजा')]\n",
    "english_word_vector = en_embeddings[vocab_en.index('king')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e087949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.05191034]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(hindi_word_vector.reshape(1,-1), english_word_vector.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94395e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english embeddings shape (32340, 300) hindi embeddings shape (32340, 300)\n"
     ]
    }
   ],
   "source": [
    "# read the file where english and hindi words present\n",
    "# separate hindi and english words\n",
    "# get embeddings for the words also from respective models.\n",
    "file_name = 'en-hi.txt'\n",
    "\n",
    "eng_hin_lexicon = []\n",
    "english_embs_lexicon = []\n",
    "hindi_emds_lexicon = []\n",
    "\n",
    "with open(file_name, 'r') as file:\n",
    "    for line in file:\n",
    "        words = line.split('\\t')\n",
    "        eng = words[0]\n",
    "        hin = words[1].split('\\n')[0]\n",
    "        if eng in vocab_en and hin in vocab_hi:\n",
    "            eng_hin_lexicon.append((eng, hin))\n",
    "            hin_vector = hi_embeddings[vocab_hi.index(hin)]\n",
    "            eng_vector = en_embeddings[vocab_en.index(eng)]\n",
    "            english_embs_lexicon.append(eng_vector)\n",
    "            hindi_emds_lexicon.append(hin_vector)\n",
    "english_embs_lexicon = np.array(english_embs_lexicon)\n",
    "hindi_emds_lexicon = np.array(hindi_emds_lexicon)\n",
    "print('english embeddings shape', english_embs_lexicon.shape, 'hindi embeddings shape', hindi_emds_lexicon.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43aee1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For whole file en-hi.txt\n"
     ]
    }
   ],
   "source": [
    "print('For whole file en-hi.txt')\n",
    "\n",
    "combined = list(zip(english_embs_lexicon, hindi_emds_lexicon, eng_hin_lexicon))\n",
    "random.shuffle(combined)\n",
    "english_embs_lexicon_whole, hindi_emds_lexicon_whole, eng_hin_lexicon_whole = zip(*combined)\n",
    "english_embs_lexicon_whole = list(english_embs_lexicon_whole)\n",
    "hindi_emds_lexicon_whole = list(hindi_emds_lexicon_whole)\n",
    "eng_hin_lexicon_whole = list(eng_hin_lexicon_whole)\n",
    "\n",
    "# take last 5000 into test and remaining in train set.\n",
    "english_embs_lexicon_train, hindi_emds_lexicon_train, eng_hin_lexicon_train = english_embs_lexicon_whole[:-5000], hindi_emds_lexicon_whole[:-5000], eng_hin_lexicon_whole[:-5000]\n",
    "english_embs_lexicon_test, hindi_emds_lexicon_test, eng_hin_lexicon_test = english_embs_lexicon_whole[-5000:], hindi_emds_lexicon_whole[-5000:], eng_hin_lexicon_whole[-5000:]\n",
    "\n",
    "del english_embs_lexicon_whole, hindi_emds_lexicon_whole, eng_hin_lexicon_whole\n",
    "del english_embs_lexicon, hindi_emds_lexicon, eng_hin_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7d3ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_embs_lexicon_train = np.array(english_embs_lexicon_train)\n",
    "hindi_emds_lexicon_train = np.array(hindi_emds_lexicon_train)\n",
    "english_embs_lexicon_test = np.array(english_embs_lexicon_test)\n",
    "hindi_emds_lexicon_test = np.array(hindi_emds_lexicon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3508f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the covariance matrix between source and target embeddings\n",
    "M = np.dot(english_embs_lexicon_train.T, hindi_emds_lexicon_train)\n",
    "# Perform SVD to obtain the orthogonal matrix R\n",
    "U, s, Vt = np.linalg.svd(M)\n",
    "R = np.dot(U, Vt)\n",
    "#aligned_embeddings = np.dot(english_vocab_embeddings, R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60c1a9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set precision values\n",
      "precision@1 0.183\n",
      "precision@5 0.311\n",
      "The test set (unseen pairs) precision values\n",
      "precision@1 0.126\n",
      "precision@5 0.253\n"
     ]
    }
   ],
   "source": [
    "# Precision@1 and Precision@5 accuracy\n",
    "def precision(word_set, R, hindi_vocab_embeddings, vocab_hi, en_embeddings, vocab_en, k= 5):\n",
    "    p_1 = 0\n",
    "    p_5 = 0\n",
    "    for i, (eng, hin) in enumerate(word_set):\n",
    "        word_vector = en_embeddings[vocab_en.index(eng)]\n",
    "        word_vector = en_embeddings[vocab_en.index(eng)]\n",
    "        aligned_vector = np.dot(word_vector, R)\n",
    "        aligned_vector = aligned_vector.reshape(1, -1)\n",
    "        similarities = cosine_similarity(aligned_vector, hindi_vocab_embeddings)[0]\n",
    "        most_similar_idx = similarities.argsort()[-k:][::-1]\n",
    "        sims = [vocab_hi[top] for top in most_similar_idx]\n",
    "        \n",
    "        if sims[0] == hin:\n",
    "            p_1 += 1\n",
    "        if hin in sims:\n",
    "            p_5 += 1\n",
    "    print('precision@1' ,p_1 / len(word_set))\n",
    "    print('precision@5', p_5 / len(word_set))\n",
    "    \n",
    "print('The train set precision values') \n",
    "precision(eng_hin_lexicon_train[:1000], R, hi_embeddings.vectors, vocab_hi, en_embeddings, vocab_en, k = 5)\n",
    "\n",
    "print('The test set (unseen pairs) precision values') \n",
    "precision(eng_hin_lexicon_test[:1000], R, hi_embeddings.vectors, vocab_hi, en_embeddings, vocab_en, k = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27935979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity after alignment  0.011440736 similarity before alignment  0.008342263\n"
     ]
    }
   ],
   "source": [
    "# get aligned embeddings for train set \n",
    "# for every word pair get aligned (after alignment) and non aligned (before alignment) embeddings\n",
    "# get mean similarity over all pairs\n",
    "\n",
    "aligned_en_embeddings = np.dot(english_embs_lexicon_train, R)\n",
    "\n",
    "def similarity_analysis(word_set, english_embds, hindi_embds, aligned_en_embeddings):\n",
    "    aligned_simi = []\n",
    "    unaligned_simi = []\n",
    "    for i, (eng, hin) in enumerate(word_set):\n",
    "        eng_vect = english_embds[i]\n",
    "        hin_vect = hindi_embds[i]\n",
    "        hin_aligned_vect = aligned_en_embeddings[i]\n",
    "        similarity_after = cosine_similarity(eng_vect.reshape(1, -1), hin_aligned_vect.reshape(1, -1))[0][0]\n",
    "        similarity_before = cosine_similarity(eng_vect.reshape(1, -1), hin_vect.reshape(1, -1))[0][0]\n",
    "        aligned_simi.append(similarity_after)\n",
    "        unaligned_simi.append(similarity_before)\n",
    "    return aligned_simi, unaligned_simi\n",
    "        \n",
    "aligned_simi, unaligned_simi = similarity_analysis(eng_hin_lexicon_train, english_embs_lexicon_train, hindi_emds_lexicon_train, aligned_en_embeddings) \n",
    "print('similarity after alignment ',np.mean(aligned_simi), 'similarity before alignment ',np.mean(unaligned_simi))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eedc6da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set precision values\n",
      "English: hands Hindi: हाथ Predicted hindi: हाथ with cosine similarity: 0.6519642\n",
      "English: ruckus Hindi: हंगामा Predicted hindi: हुड़दंग with cosine similarity: 0.47384137\n",
      "English: indent Hindi: हाशिये Predicted hindi: wrapper:tag with cosine similarity: 0.4393165\n",
      "English: lek Hindi: लेक Predicted hindi: बेमरंग्बन with cosine similarity: 0.39674598\n",
      "English: kuna Hindi: कुना Predicted hindi: पीसोMYR with cosine similarity: 0.45688576\n",
      "English: raven Hindi: रेवेन Predicted hindi: लाँगबॉटम with cosine similarity: 0.44949812\n",
      "English: affinity Hindi: अपनापन Predicted hindi: अंतर्संबद्धता with cosine similarity: 0.4434074\n",
      "English: roles Hindi: भूमिकाएँ Predicted hindi: भूमिकाओं with cosine similarity: 0.49793386\n",
      "English: nigerian Hindi: नाइजीरियाई Predicted hindi: अफ्रीकाः with cosine similarity: 0.50330544\n",
      "English: viruses Hindi: वाइरस Predicted hindi: वायरस with cosine similarity: 0.59939754\n",
      "\n",
      "\n",
      "The test set (unseen pairs) precision values\n",
      "English: edis Hindi: एडिस Predicted hindi: फॉरजेड with cosine similarity: 0.42466432\n",
      "English: front Hindi: सामने Predicted hindi: बगल with cosine similarity: 0.5281441\n",
      "English: councillor Hindi: पार्षद Predicted hindi: पार्षदाें with cosine similarity: 0.4645879\n",
      "English: its Hindi: इसकी Predicted hindi: इसकी with cosine similarity: 0.5375196\n",
      "English: violin Hindi: वायलिन Predicted hindi: वायलिन with cosine similarity: 0.5389761\n",
      "English: gastroenteritis Hindi: gastroenteritis Predicted hindi: आंत्रशोथ with cosine similarity: 0.5138856\n",
      "English: davydenko Hindi: डेवीडेंको Predicted hindi: जाकोविच with cosine similarity: 0.53353024\n",
      "English: mast Hindi: mast Predicted hindi: मस्तूलों with cosine similarity: 0.40644103\n",
      "English: disputed Hindi: विवादित Predicted hindi: विवाद with cosine similarity: 0.4504298\n",
      "English: pak Hindi: pak Predicted hindi: सेनपाकिस्तान with cosine similarity: 0.50651467\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def translate_word(en_embeddings, word_set, R, hi_embeddings, vocab_hi, vocab_en):\n",
    "    \n",
    "    for i, (eng, hin) in enumerate(word_set):\n",
    "        word_vector = en_embeddings[vocab_en.index(eng)]\n",
    "        aligned_vector = np.dot(word_vector, R)\n",
    "        aligned_vector = aligned_vector.reshape(1, -1)\n",
    "        similarities = cosine_similarity(aligned_vector, hi_embeddings.vectors)[0]\n",
    "        similarity_of_first = max(similarities)\n",
    "        most_similar_idx = similarities.argmax()\n",
    "        sims = vocab_hi[most_similar_idx] \n",
    "        print('English:',eng ,'Hindi:', hin, 'Predicted hindi:',sims, 'with cosine similarity:', similarity_of_first)\n",
    "        \n",
    "print('The train set precision values') \n",
    "translate_word(en_embeddings, eng_hin_lexicon_train[:10], R, hi_embeddings, vocab_hi, vocab_en)\n",
    "print('\\n')\n",
    "print('The test set (unseen pairs) precision values') \n",
    "translate_word(en_embeddings, eng_hin_lexicon_test[:10], R, hi_embeddings, vocab_hi, vocab_en)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6dfffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation(english_embs_lexicon_train, hindi_emds_lexicon_train, eng_hin_lexicon_train, english_embs_lexicon_test, hindi_emds_lexicon_test, eng_hin_lexicon_test, vocab_en, vocab_hi, en_embeddings, hi_embeddings):\n",
    "    english_embs_lexicon_train = np.array(english_embs_lexicon_train)\n",
    "    hindi_emds_lexicon_train = np.array(hindi_emds_lexicon_train)\n",
    "    \n",
    "    M = np.dot(english_embs_lexicon_train.T, hindi_emds_lexicon_train)\n",
    "    U, s, Vt = np.linalg.svd(M)\n",
    "    R = np.dot(U, Vt)\n",
    "    print('The train set precision values') \n",
    "    precision(eng_hin_lexicon_train[:1000], R, hi_embeddings.vectors, vocab_hi, en_embeddings, vocab_en, k = 5)\n",
    "    print('\\n')\n",
    "    print('The test set (unseen pairs) precision values') \n",
    "    precision(eng_hin_lexicon_test[:1000], R, hi_embeddings.vectors, vocab_hi, en_embeddings, vocab_en, k = 5)\n",
    "\n",
    "\n",
    "    aligned_en_embeddings = np.dot(english_embs_lexicon_train, R)\n",
    "    print('\\n')\n",
    "    aligned_simi, unaligned_simi = similarity_analysis(eng_hin_lexicon_train, english_embs_lexicon_train, hindi_emds_lexicon_train, aligned_en_embeddings) \n",
    "    print('\\n')\n",
    "    print('similarity after alignment ',np.mean(aligned_simi), 'similarity before alignment ',np.mean(unaligned_simi))\n",
    "    \n",
    "    print('\\n')\n",
    "    print('translated words - seen pairs')\n",
    "    translate_word(en_embeddings, eng_hin_lexicon_train[:10], R, hi_embeddings, vocab_hi, vocab_en)\n",
    "    print('\\n')\n",
    "    print('translated words - unseen pairs')\n",
    "    translate_word(en_embeddings, eng_hin_lexicon_test[:10], R, hi_embeddings, vocab_hi, vocab_en)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f425821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set precision values\n",
      "precision@1 0.266\n",
      "precision@5 0.415\n",
      "\n",
      "\n",
      "The test set (unseen pairs) precision values\n",
      "precision@1 0.094\n",
      "precision@5 0.195\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "similarity after alignment  0.011470868 similarity before alignment  0.009003754\n",
      "\n",
      "\n",
      "translated words - seen pairs\n",
      "English: hands Hindi: हाथ Predicted hindi: हाथ with cosine similarity: 0.6022275\n",
      "English: ruckus Hindi: हंगामा Predicted hindi: हुड़दंग with cosine similarity: 0.41569775\n",
      "English: indent Hindi: हाशिये Predicted hindi: CTRL with cosine similarity: 0.43581644\n",
      "English: lek Hindi: लेक Predicted hindi: लेक with cosine similarity: 0.65189576\n",
      "English: kuna Hindi: कुना Predicted hindi: पीसोMYR with cosine similarity: 0.41060355\n",
      "English: raven Hindi: रेवेन Predicted hindi: मोसेली with cosine similarity: 0.44332454\n",
      "English: affinity Hindi: अपनापन Predicted hindi: अंतर्संबद्धता with cosine similarity: 0.39857852\n",
      "English: roles Hindi: भूमिकाएँ Predicted hindi: भूमिकाएँ with cosine similarity: 0.46996263\n",
      "English: nigerian Hindi: नाइजीरियाई Predicted hindi: अफ्रीकाअमेरिकाएशियायूरोपमध्य with cosine similarity: 0.5022264\n",
      "English: viruses Hindi: वाइरस Predicted hindi: वायरस with cosine similarity: 0.5785912\n",
      "\n",
      "\n",
      "translated words - unseen pairs\n",
      "English: edis Hindi: एडिस Predicted hindi: आएलैंड with cosine similarity: 0.43247128\n",
      "English: front Hindi: सामने Predicted hindi: सामने with cosine similarity: 0.4470095\n",
      "English: councillor Hindi: पार्षद Predicted hindi: जनप्रतिनिधयों with cosine similarity: 0.43252182\n",
      "English: its Hindi: इसकी Predicted hindi: इसकी with cosine similarity: 0.45273936\n",
      "English: violin Hindi: वायलिन Predicted hindi: संगीतवादन with cosine similarity: 0.44182146\n",
      "English: gastroenteritis Hindi: gastroenteritis Predicted hindi: कोलाइटिस with cosine similarity: 0.49575508\n",
      "English: davydenko Hindi: डेवीडेंको Predicted hindi: जाकोविच with cosine similarity: 0.55178636\n",
      "English: mast Hindi: mast Predicted hindi: खम्भें with cosine similarity: 0.4072425\n",
      "English: disputed Hindi: विवादित Predicted hindi: विवादित with cosine similarity: 0.42386115\n",
      "English: pak Hindi: pak Predicted hindi: उसामा with cosine similarity: 0.4765336\n"
     ]
    }
   ],
   "source": [
    "#with different dictionary sizes\n",
    "ablation(english_embs_lexicon_train[:5000], hindi_emds_lexicon_train[:5000], eng_hin_lexicon_train[:5000], english_embs_lexicon_test, hindi_emds_lexicon_test, eng_hin_lexicon_test, vocab_en, vocab_hi, en_embeddings, hi_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b2f4fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set precision values\n",
      "precision@1 0.193\n",
      "precision@5 0.35\n",
      "\n",
      "\n",
      "The test set (unseen pairs) precision values\n",
      "precision@1 0.103\n",
      "precision@5 0.219\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "similarity after alignment  0.010376268 similarity before alignment  0.008341992\n",
      "\n",
      "\n",
      "translated words - seen pairs\n",
      "English: hands Hindi: हाथ Predicted hindi: हाथ with cosine similarity: 0.65525377\n",
      "English: ruckus Hindi: हंगामा Predicted hindi: आक्रोष with cosine similarity: 0.42692068\n",
      "English: indent Hindi: हाशिये Predicted hindi: CTRL with cosine similarity: 0.4433787\n",
      "English: lek Hindi: लेक Predicted hindi: लेक with cosine similarity: 0.506214\n",
      "English: kuna Hindi: कुना Predicted hindi: पीसोMYR with cosine similarity: 0.44070446\n",
      "English: raven Hindi: रेवेन Predicted hindi: हरमाईनी with cosine similarity: 0.44423327\n",
      "English: affinity Hindi: अपनापन Predicted hindi: अंतर्संबद्धता with cosine similarity: 0.4478989\n",
      "English: roles Hindi: भूमिकाएँ Predicted hindi: भूमिकाएँ with cosine similarity: 0.50458145\n",
      "English: nigerian Hindi: नाइजीरियाई Predicted hindi: अफ्रीकाना with cosine similarity: 0.49658823\n",
      "English: viruses Hindi: वाइरस Predicted hindi: वायरस with cosine similarity: 0.5694108\n",
      "\n",
      "\n",
      "translated words - unseen pairs\n",
      "English: edis Hindi: एडिस Predicted hindi: आएलैंड with cosine similarity: 0.40768152\n",
      "English: front Hindi: सामने Predicted hindi: सामने with cosine similarity: 0.48437136\n",
      "English: councillor Hindi: पार्षद Predicted hindi: उपमेयर with cosine similarity: 0.48169968\n",
      "English: its Hindi: इसकी Predicted hindi: इसकी with cosine similarity: 0.48725736\n",
      "English: violin Hindi: वायलिन Predicted hindi: वायलिन with cosine similarity: 0.48095876\n",
      "English: gastroenteritis Hindi: gastroenteritis Predicted hindi: meningococcaemia with cosine similarity: 0.4689428\n",
      "English: davydenko Hindi: डेवीडेंको Predicted hindi: योकोविच with cosine similarity: 0.5231801\n",
      "English: mast Hindi: mast Predicted hindi: ऐटेना with cosine similarity: 0.40597954\n",
      "English: disputed Hindi: विवादित Predicted hindi: विवादलेख with cosine similarity: 0.43322024\n",
      "English: pak Hindi: pak Predicted hindi: पाक with cosine similarity: 0.52749634\n"
     ]
    }
   ],
   "source": [
    "ablation(english_embs_lexicon_train[:10000], hindi_emds_lexicon_train[:10000], eng_hin_lexicon_train[:10000], english_embs_lexicon_test, hindi_emds_lexicon_test, eng_hin_lexicon_test, vocab_en, vocab_hi, en_embeddings, hi_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d1022a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train set precision values\n",
      "precision@1 0.185\n",
      "precision@5 0.324\n",
      "\n",
      "\n",
      "The test set (unseen pairs) precision values\n",
      "precision@1 0.121\n",
      "precision@5 0.248\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "similarity after alignment  0.009675078 similarity before alignment  0.007982716\n",
      "\n",
      "\n",
      "translated words - seen pairs\n",
      "English: hands Hindi: हाथ Predicted hindi: हाथों with cosine similarity: 0.65998125\n",
      "English: ruckus Hindi: हंगामा Predicted hindi: हुड़दंग with cosine similarity: 0.48993558\n",
      "English: indent Hindi: हाशिये Predicted hindi: CTRL with cosine similarity: 0.4353192\n",
      "English: lek Hindi: लेक Predicted hindi: लेक with cosine similarity: 0.41450316\n",
      "English: kuna Hindi: कुना Predicted hindi: पीसोMYR with cosine similarity: 0.4715731\n",
      "English: raven Hindi: रेवेन Predicted hindi: लोबोरहाम्फुस with cosine similarity: 0.43840784\n",
      "English: affinity Hindi: अपनापन Predicted hindi: अंतर्संबद्धता with cosine similarity: 0.4422865\n",
      "English: roles Hindi: भूमिकाएँ Predicted hindi: भूमिकाओं with cosine similarity: 0.49805602\n",
      "English: nigerian Hindi: नाइजीरियाई Predicted hindi: सूडानीज with cosine similarity: 0.50198674\n",
      "English: viruses Hindi: वाइरस Predicted hindi: वायरस with cosine similarity: 0.60307866\n",
      "\n",
      "\n",
      "translated words - unseen pairs\n",
      "English: edis Hindi: एडिस Predicted hindi: आएलैंड with cosine similarity: 0.44277245\n",
      "English: front Hindi: सामने Predicted hindi: बगल with cosine similarity: 0.52321273\n",
      "English: councillor Hindi: पार्षद Predicted hindi: पार्षदाें with cosine similarity: 0.48065284\n",
      "English: its Hindi: इसकी Predicted hindi: इसकी with cosine similarity: 0.5047025\n",
      "English: violin Hindi: वायलिन Predicted hindi: वायलिन with cosine similarity: 0.52525574\n",
      "English: gastroenteritis Hindi: gastroenteritis Predicted hindi: आंत्रशोथ with cosine similarity: 0.49241182\n",
      "English: davydenko Hindi: डेवीडेंको Predicted hindi: डोकोविक with cosine similarity: 0.53380054\n",
      "English: mast Hindi: mast Predicted hindi: मस्तूलों with cosine similarity: 0.41655535\n",
      "English: disputed Hindi: विवादित Predicted hindi: विवाद with cosine similarity: 0.43785906\n",
      "English: pak Hindi: pak Predicted hindi: शरजील with cosine similarity: 0.5005091\n"
     ]
    }
   ],
   "source": [
    "ablation(english_embs_lexicon_train[:20000], hindi_emds_lexicon_train[:20000], eng_hin_lexicon_train[:20000], english_embs_lexicon_test, hindi_emds_lexicon_test, eng_hin_lexicon_test, vocab_en, vocab_hi, en_embeddings, hi_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d373df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395c3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
